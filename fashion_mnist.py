# -*- coding: utf-8 -*-
"""Fashion MNIST

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15HSs0kktuCZIVEcevURisyOL-yibGXyD
"""

import tensorflow as tf
from tensorflow import keras
import numpy as np
import matplotlib.pyplot as plt
import time

fashion_mnist = keras.datasets.fashion_mnist

(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()
class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 
               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

train_images = train_images / 255.0

test_images = test_images / 255.0

mean_train_images = np.mean(train_images)
train_images = train_images - mean_train_images
test_images = test_images - mean_train_images

train_images = train_images[..., np.newaxis]
test_images = test_images[..., np.newaxis]

datagen_training = keras.preprocessing.image.ImageDataGenerator(
    horizontal_flip=True,
    fill_mode='nearest')

datagen_training.fit(train_images)

datagen_validation = keras.preprocessing.image.ImageDataGenerator()
datagen_validation.fit(train_images)

model = keras.Sequential()

model.add(keras.layers.Conv2D(64, (3,3), padding='same', input_shape=(28, 28, 1)))
model.add(keras.layers.Conv2D(64, (3,3), padding='same', use_bias=False))
model.add(keras.layers.BatchNormalization())
model.add(keras.layers.Activation('relu'))
model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))
model.add(keras.layers.Dropout(0.1))

model.add(keras.layers.Conv2D(128, (3,3), padding='same'))
model.add(keras.layers.Conv2D(128, (3,3), padding='same', use_bias=False))
model.add(keras.layers.BatchNormalization())
model.add(keras.layers.Activation('relu'))
model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))
model.add(keras.layers.Dropout(0.3))

model.add(keras.layers.Flatten(input_shape=(28, 28)))
model.add(keras.layers.Dense(256, kernel_initializer='random_uniform', use_bias=False))
model.add(keras.layers.BatchNormalization())
model.add(keras.layers.Activation('relu'))
model.add(keras.layers.Dropout(0.5))
model.add(keras.layers.Dense(64, kernel_initializer='random_uniform', use_bias=False))
model.add(keras.layers.BatchNormalization())
model.add(keras.layers.Activation('relu'))
model.add(keras.layers.Dropout(0.5))
model.add(keras.layers.Dense(10, kernel_initializer='random_uniform', use_bias=False))
model.add(keras.layers.BatchNormalization())
model.add(keras.layers.Activation('softmax'))

my_callback = keras.callbacks.EarlyStopping(monitor='val_acc', min_delta=0, patience=15, verbose=0, mode='auto', baseline=None)

model.compile(optimizer=tf.train.AdamOptimizer(), 
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

start_training = time.time()
history = model.fit_generator(datagen_training.flow(train_images, train_labels, batch_size=256),
                    steps_per_epoch=len(train_images) * 0.7 / 256, epochs=120,
                    validation_data=datagen_validation.flow(train_images, train_labels, batch_size=256),
                    validation_steps=len(train_images) * 0.3 / 256,
                    callbacks = [my_callback])

end_training = time.time()
training_time = end_training - start_training
print('Total time of training: ', training_time)

start_testing = time.time()
test_loss, test_acc = model.evaluate(test_images, test_labels)
end_testing = time.time()
testing_time = end_testing - start_testing
print('Test accuracy:', test_acc)
print('Total time of testing: ', testing_time)

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper right')
plt.show()

plt.plot(history.history['acc'])
plt.plot(history.history['val_acc'])
plt.title('Model Accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='lower right')
plt.show()